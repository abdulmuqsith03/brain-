{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c5a26e-1d8e-4ab6-b46e-9d78d8d1c698",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f7d4e6-0a0b-4328-861a-4ab67ff53b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muqsi\\anaconda3\\envs\\brain\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\muqsi\\anaconda3\\envs\\brain\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Activation, BatchNormalization, Multiply, Add\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf3cb8-906a-4339-8470-8c0fe498345b",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data (Using PSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee01834-7054-4ae5-aa25-ff97b161bf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "X_train shape: (179, 128, 128, 1), y_train shape: (179, 128, 128, 1)\n",
      "X_test shape: (45, 128, 128, 1), y_test shape: (45, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_nii_images(directory, img_size=(128, 128)):\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    for folder in os.listdir(directory):\n",
    "        folder_path = os.path.join(directory, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file in os.listdir(folder_path):\n",
    "                if file.endswith('.nii') or file.endswith('.nii.gz'):\n",
    "                    img_path = os.path.join(folder_path, file)\n",
    "                    img_data = nib.load(img_path).get_fdata()\n",
    "                    \n",
    "                    # Normalize image data\n",
    "                    img_data = np.interp(img_data, (img_data.min(), img_data.max()), (0, 1))\n",
    "                    \n",
    "                    # Handle cases where mask is missing\n",
    "                    if img_data.shape[-1] > 1:\n",
    "                        img_slices = img_data[:, :, :-1]  # Image\n",
    "                        mask_slice = img_data[:, :, -1]   # Last slice as mask\n",
    "                    else:\n",
    "                        img_slices = img_data\n",
    "                        mask_slice = np.zeros_like(img_slices)  # Create blank mask if missing\n",
    "\n",
    "                    # Resize images and masks\n",
    "                    img_resized = np.array([\n",
    "                        tf.image.resize(img_slices[:, :, i][..., np.newaxis], img_size).numpy()\n",
    "                        for i in range(img_slices.shape[-1])\n",
    "                    ])\n",
    "                    \n",
    "                    mask_resized = tf.image.resize(mask_slice[..., np.newaxis], img_size).numpy()\n",
    "                    \n",
    "                    # Append to dataset\n",
    "                    images.append(img_resized)\n",
    "                    masks.append(mask_resized)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    images = np.array(images).reshape(-1, img_size[0], img_size[1], 1)\n",
    "    masks = np.array(masks).reshape(-1, img_size[0], img_size[1], 1)\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "# Load data\n",
    "data_dir = \"../data/brats-men-train\"\n",
    "X, y = load_nii_images(data_dir)\n",
    "\n",
    "# Ensure equal shape before splitting\n",
    "min_len = min(len(X), len(y))\n",
    "X, y = X[:min_len], y[:min_len]\n",
    "\n",
    "# Normalize masks for binary classification\n",
    "y = (y > 0.5).astype(\"float32\")\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print dataset info\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3296f795-ce85-4b3b-a599-2a7467f9730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessing pipeline\n",
    "with open(\"../models/preprocessing.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"X_train\": X_train, \"X_test\": X_test, \"y_train\": y_train, \"y_test\": y_test}, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ccae77-7dcb-49dc-883a-953bb897d434",
   "metadata": {},
   "source": [
    "### Define Attention Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d0598d-ef5e-4e18-ad28-b13c5792b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_block(x, g):\n",
    "    theta_x = Conv2D(64, (1, 1), padding=\"same\")(x)\n",
    "    phi_g = Conv2D(64, (1, 1), padding=\"same\")(g)\n",
    "    phi_g = UpSampling2D(size=(2, 2), interpolation='bilinear')(phi_g)\n",
    "    \n",
    "    f = Activation(\"relu\")(Add()([theta_x, phi_g]))\n",
    "    psi_f = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(f)\n",
    "    \n",
    "    return Multiply()([x, psi_f])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4c052d-c8e2-4ee5-8ec2-39387bfe6f0c",
   "metadata": {},
   "source": [
    "### Define Attention U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a656e46-f183-46e6-895a-8afbfaf8c08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\muqsi\\anaconda3\\envs\\brain\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\muqsi\\anaconda3\\envs\\brain\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 128, 128, 64)         640       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 64, 64, 64)           0         ['conv2d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 128)          73856     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 32, 32, 128)          0         ['conv2d_1[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 256)          295168    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 64)           16448     ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 64)           8256      ['conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2  (None, 64, 64, 64)           0         ['conv2d_4[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 64, 64, 64)           0         ['conv2d_3[0][0]',            \n",
      "                                                                     'up_sampling2d[0][0]']       \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 64, 64, 64)           0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 1)            65        ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " multiply (Multiply)         (None, 64, 64, 128)          0         ['conv2d_1[0][0]',            \n",
      "                                                                     'conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSamplin  (None, 64, 64, 256)          0         ['conv2d_2[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 64, 64, 384)          0         ['multiply[0][0]',            \n",
      "                                                                     'up_sampling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 128)          442496    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 64, 64, 64)           8256      ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 128, 128, 64)         4160      ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSamplin  (None, 128, 128, 64)         0         ['conv2d_8[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 128, 128, 64)         0         ['conv2d_7[0][0]',            \n",
      "                                                                     'up_sampling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 128, 128, 64)         0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 128, 128, 1)          65        ['activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)       (None, 128, 128, 64)         0         ['conv2d[0][0]',              \n",
      "                                                                     'conv2d_9[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSamplin  (None, 128, 128, 128)        0         ['conv2d_6[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 128, 128, 192)        0         ['multiply_1[0][0]',          \n",
      " )                                                                   'up_sampling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 128, 128, 64)         110656    ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 128, 128, 1)          65        ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 960131 (3.66 MB)\n",
      "Trainable params: 960131 (3.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_attention_unet(input_shape=(128, 128, 1)):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    bottleneck = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
    "    \n",
    "    # Decoder\n",
    "    attn1 = attention_block(conv2, bottleneck)\n",
    "    up1 = UpSampling2D((2, 2))(bottleneck)\n",
    "    merge1 = concatenate([attn1, up1], axis=-1)\n",
    "    conv3 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(merge1)\n",
    "    \n",
    "    attn2 = attention_block(conv1, conv3)\n",
    "    up2 = UpSampling2D((2, 2))(conv3)\n",
    "    merge2 = concatenate([attn2, up2], axis=-1)\n",
    "    conv4 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(merge2)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation=\"sigmoid\")(conv4)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "model = build_attention_unet()\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd58aa7f-5a4c-44ad-8864-f7ee07254387",
   "metadata": {},
   "source": [
    "### Train the Model with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7786e9-4afa-44fa-9eee-923c3550c5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\muqsi\\anaconda3\\envs\\brain\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\muqsi\\anaconda3\\envs\\brain\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "23/23 [==============================] - 87s 4s/step - loss: 0.6693 - accuracy: 0.9950 - val_loss: 0.5836 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      " 4/23 [====>.........................] - ETA: 1:09 - loss: 0.5518 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=20,\n",
    "    batch_size=8,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84f8a9-d551-43ab-8d39-687aad9acd61",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289920f-4d0f-41fd-9074-4a8a9a80189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model.save(\"../models/attention_unet_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c72a1d3-4f28-43a4-9314-de65617cbcb8",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be12848-73ad-4690-8e56-96186b3772bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the segmentation file\n",
    "file_path = r\"C:\\Users\\RAHUL\\Desktop\\brain\\data\\brats-men-train\\BraTS-MEN-00012-000\\BraTS-MEN-00012-000-t1c.nii\"  # Change this to the correct path\n",
    "seg_img = nib.load(file_path).get_fdata()\n",
    "\n",
    "# Select the middle slice for visualization\n",
    "mid_slice = seg_img.shape[2] // 2\n",
    "seg_slice = seg_img[:, :, mid_slice]\n",
    "\n",
    "# Calculate tumor size (number of nonzero pixels)\n",
    "tumor_pixels = np.sum(seg_slice > 0)  # Count tumor pixels\n",
    "total_pixels = seg_slice.shape[0] * seg_slice.shape[1]  # Total pixels in the slice\n",
    "tumor_percentage = (tumor_pixels / total_pixels) * 100  # Calculate percentage\n",
    "\n",
    "# Display the segmentation mask with tumor percentage\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.title(f\"Tumor Segmentation (Middle Slice)\\nTumor Size: {tumor_pixels} pixels ({tumor_percentage:.2f}%)\")\n",
    "plt.imshow(seg_slice, cmap=\"jet\")\n",
    "plt.colorbar(label=\"Segmentation Labels\")\n",
    "plt.show()\n",
    "\n",
    "# Print tumor size and percentage\n",
    "print(f\"Tumor Size: {tumor_pixels} pixels\")\n",
    "print(f\"Tumor Percentage: {tumor_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b05bfb-3433-489c-a55a-33c9993d4a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1a6702-768f-4725-921f-c9391c0fa55c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
